{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Car Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K-Nearest Neighbors Algorithm(KNN) To Predict Car Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In this project, a thorough machine learning workflow is used to predict a car's market price using its attributes. The data set used contains information on various cars. For each car we have information about the technical aspects of the vehicle such as the motor's displacement, the weight of the car, the miles per gallon, how fast the car accelerates, and more. You can read more about the data set <https://archive.ics.uci.edu/ml/datasets/automobile>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'imports-85.data' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-538bbe580cad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#load and preview the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imports-85.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m99\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'imports-85.data' does not exist"
     ]
    }
   ],
   "source": [
    "#load and preview the dataset\n",
    "\n",
    "cars = pd.read_csv('imports-85.data')\n",
    "pd.options.display.max_columns = 99\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As seen above, the column names are not the same as seen in the link above <https://archive.ics.uci.edu/ml/datasets/automobile> this is corrected manually below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', \n",
    "'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', \n",
    "'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', \n",
    "'stroke', 'compression-ratio', 'horsepower', 'peak-rpm',  'city-mpg', 'highway-mpg', 'price']\n",
    "\n",
    "cars.columns = col_names\n",
    "cars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From the first five rows above, we see some entries have '?' (normalized-losses column), for the machine learning algorithm to work, wewe need to deal effectively with this__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all '?' with nan values in the dataset\n",
    "\n",
    "cars.replace('?',np.nan,inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the summary of the dataset for some insights\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Since we see some columns have nan values, we will attempt to have a more detailed count of which columns have Nan values and how many Nan values each column has__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since it the price we are trying to predict, we will drop rows with na values from the price column\n",
    "cars.dropna(subset=['price'], inplace=True)\n",
    "cars['price'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In order to fill the remaining columns with their mean, we need to convert some columns that are numeric but stored as object type. These columns need to be converted to float__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert specific columns to float type\n",
    "cars[['bore','stroke','horsepower','peak-rpm','normalized-losses','price']] = cars[['bore','stroke',\n",
    "                                                        'horsepower','peak-rpm','normalized-losses','price']].astype('float64')\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill each column that have Nan values with the mean of the column\n",
    "cars.fillna(np.mean(cars), inplace=True)\n",
    "cars.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset of numeric values only for the prediction\n",
    "numeric_cars = cars.copy()\n",
    "continuous_values_cols = ['normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'bore', 'stroke', \n",
    "                          'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "numeric_cars = numeric_cars[continuous_values_cols]\n",
    "numeric_cars.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview the numeric dataset after cleaning\n",
    "numeric_cars.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns apart from the price colum which we want to predict, should be normalized so that each feature contributes approximately proportionately to the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to normalize, we use standardization: x-(mean)/std()\n",
    "#Create a normalized dataframe\n",
    "\n",
    "normalized_cars = (numeric_cars - numeric_cars.mean()) / numeric_cars.std()\n",
    "normalized_cars['price'] = numeric_cars['price']\n",
    "normalized_cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  K-Nearest Neighbors Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#univariate k-nearest neighbors model\n",
    "\n",
    "def knn_train_test(train_col, target_col, df):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    df = df.reindex(shuffled_index)\n",
    "    \n",
    "    #split the dataset into two equal parts, i.e Holdout Validation\n",
    "    v = int((df.shape[0])/2)\n",
    "    \n",
    "    train_df = df[:v]\n",
    "    test_df = df[v:]\n",
    "    knn = KNeighborsRegressor()\n",
    "    knn.fit(train_df[[train_col]], train_df[target_col])\n",
    "    price = knn.predict(test_df[[train_col]])\n",
    "    \n",
    "    #Calculate and return the root mean square value\n",
    "    rmse = np.sqrt(mean_squared_error(test_df[target_col],price))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the price using each column as a feature and see which one performs best\n",
    "feature = ['normalized-losses', 'wheel-base', 'length', 'width', 'height',\n",
    "       'curb-weight', 'bore', 'stroke', 'compression-ratio', 'horsepower',\n",
    "       'peak-rpm', 'city-mpg', 'highway-mpg']\n",
    "\n",
    "rmse_vals = {}\n",
    "for i in feature:\n",
    "    tr_col = i\n",
    "    tar_col = 'price'\n",
    "    result = knn_train_test(tr_col, tar_col, normalized_cars)\n",
    "    rmse_vals[i] = result\n",
    "    \n",
    "rmse_vals\n",
    "rmse_vals_series = pd.Series(rmse_vals)\n",
    "rmse_vals_series.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the result\n",
    "%matplotlib inline\n",
    "style.use('fivethirtyeight')\n",
    "rmse_vals_series.plot(kind='bar',\n",
    "                      label='Price',\n",
    "                      figsize=(12,5),\n",
    "                      rot=45,\n",
    "                      colormap=plt.cm.BuGn_r)\n",
    "plt.title('Price Prediction Using Individual Features')\n",
    "plt.grid()\n",
    "plt.xlabel('Individual features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the visualization above, the highway miles per gallon gave the least root mean square error in predicting price for the default k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting price by varying the k value\n",
    "\n",
    "def knn_train_test(k_value, train_col, target_col, df):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    df = df.reindex(shuffled_index)\n",
    "    \n",
    "    #split the dataset into two equal parts, i.e Holdout Validation\n",
    "    v = int((df.shape[0])/2)\n",
    "    \n",
    "    train_df = df[:v]\n",
    "    test_df = df[v:]\n",
    "    knn = KNeighborsRegressor(n_neighbors=k_value)\n",
    "    knn.fit(train_df[[train_col]], train_df[target_col])\n",
    "    price = knn.predict(test_df[[train_col]])\n",
    "    \n",
    "    #Calculate and return the root mean square value\n",
    "    rmse = np.sqrt(mean_squared_error(test_df[target_col],price))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict price per feature for each k value\n",
    "feature = ['normalized-losses', 'wheel-base', 'length', 'width', 'height',\n",
    "       'curb-weight', 'bore', 'stroke', 'compression-ratio', 'horsepower',\n",
    "       'peak-rpm', 'city-mpg', 'highway-mpg']\n",
    "\n",
    "k = [1,3,5,7,9]\n",
    "\n",
    "rmse_values = []\n",
    "per_feature = []\n",
    "\n",
    "for n in k:\n",
    "    for i in feature:\n",
    "        p = n\n",
    "        tr_col = i\n",
    "        tar_col = 'price'\n",
    "        result = knn_train_test(p, tr_col, tar_col, normalized_cars)\n",
    "        rmse_vals[i] = result\n",
    "        per_feature.append(result)\n",
    "\n",
    "per_feature[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of rmse values and feature\n",
    "\n",
    "#Create a dictionary of values with each key assigned the correct values\n",
    "rmse_vals = {'k_value_1':per_feature[:13],'k_value_3':per_feature[13:26],\n",
    "             'k_value_5':per_feature[26:39],'k_value_7':per_feature[39:52],\n",
    "            'k_value_9':per_feature[52:65]}\n",
    "\n",
    "#Create a datframe using the dictionary\n",
    "rmse_vals_df = pd.DataFrame(rmse_vals)\n",
    "\n",
    "#Create a column that will used as the index\n",
    "rmse_vals_df['features'] = ['normalized-losses', 'wheel-base', 'length', 'width', 'height',\n",
    "       'curb-weight', 'bore', 'stroke', 'compression-ratio', 'horsepower',\n",
    "       'peak-rpm', 'city-mpg', 'highway-mpg']\n",
    "\n",
    "#Set the index\n",
    "rmse_vals_df.set_index('features',inplace=True)\n",
    "\n",
    "rmse_vals_df.sort_values('k_value_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the result\n",
    "rmse_vals_df.plot(figsize=(12,6))\n",
    "plt.grid()\n",
    "plt.xlabel('Individual Features')\n",
    "plt.title('Varying K-Value Used in Predicting Car Prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From the visualization above, we see that among the k values used, 9 seems to be the one that gives the least root mean square error__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the Best Features for Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_vals_df.sort_values('k_value_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From the result above, using the default k value, we see the top 5 features that give the least root mean square error. We will look at these features in batches to see the best__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Two Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-variate k-nearest neigbors model\n",
    "\n",
    "#Predicting price by varying the k value\n",
    "\n",
    "def knn_train_test(k_value, train_col, target_col, df):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    df = df.reindex(shuffled_index)\n",
    "    \n",
    "    #split the dataset into two equal parts, i.e Holdout Validation\n",
    "    v = int((df.shape[0])/2)\n",
    "    \n",
    "    train_df = df[:v]\n",
    "    test_df = df[v:]\n",
    "    knn = KNeighborsRegressor(n_neighbors=k_value)\n",
    "    knn.fit(train_df[train_col], train_df[target_col])\n",
    "    price = knn.predict(test_df[train_col])\n",
    "    \n",
    "    #Calculate and return the root mean square value\n",
    "    rmse = np.sqrt(mean_squared_error(test_df[target_col],price))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the two best features, horse power and highway-mpg\n",
    "features = ['highway-mpg','horsepower']\n",
    "k = [1,3,5,7,9]\n",
    "\n",
    "rmse_two = {}\n",
    "\n",
    "for i in k:\n",
    "    p = i\n",
    "    tr_col = features\n",
    "    tar_col = 'price'\n",
    "    result = knn_train_test(p, tr_col, tar_col, normalized_cars)\n",
    "    rmse_two[i] = result\n",
    "\n",
    "rmse_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the result\n",
    "rmse_ser = pd.Series(rmse_two)\n",
    "rmse_ser.plot(label='Price',figsize=(12,5))\n",
    "plt.xlabel('K Values')\n",
    "plt.xticks(np.arange(1, 10, step=2))\n",
    "plt.title('Predicting Price by Varying K-Value Based on Horse Power and Highway Mpg')\n",
    "plt.axhline(rmse_ser[5], color='Black', label = 'Default k-value(5)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Three Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the same function but selecting the best three features\n",
    "\n",
    "#Using the three best features, horse power and city mpg\n",
    "features = ['highway-mpg','horsepower','city-mpg']\n",
    "k = [1,3,5,7,9]\n",
    "\n",
    "rmse_three = {}\n",
    "per_feature = []\n",
    "\n",
    "for i in k:\n",
    "    p = i\n",
    "    tr_col = features\n",
    "    tar_col = 'price'\n",
    "    result = knn_train_test(p, tr_col, tar_col, normalized_cars)\n",
    "    rmse_three[i] = result\n",
    "\n",
    "rmse_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the result\n",
    "\n",
    "rmse_ser = pd.Series(rmse_three)\n",
    "rmse_ser.plot(label='Price',figsize=(12,5))\n",
    "plt.xlabel('K Values')\n",
    "plt.xticks(np.arange(1, 10, step=2))\n",
    "plt.title('Predicting Price by Varying K-Value Based on The best three features')\n",
    "plt.axhline(rmse_ser[5], color='orange', label = 'Default k-value(5)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Four Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the four best features, horse power, city mpg and Curb weight\n",
    "features = ['highway-mpg','horsepower','city-mpg','curb-weight']\n",
    "k = [1,3,5,7,9]\n",
    "\n",
    "rmse_four = {}\n",
    "per_feature = []\n",
    "\n",
    "for i in k:\n",
    "    p = i\n",
    "    tr_col = features\n",
    "    tar_col = 'price'\n",
    "    result = knn_train_test(p, tr_col, tar_col, normalized_cars)\n",
    "    rmse_four[i] = result\n",
    "\n",
    "rmse_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the result\n",
    "\n",
    "rmse_ser = pd.Series(rmse_four)\n",
    "rmse_ser.plot(label='Price',figsize=(12,5))\n",
    "plt.xlabel('K Values')\n",
    "plt.xticks(np.arange(1, 10, step=2))\n",
    "plt.title('Predicting Price by Varying K-Value Based on The best four features')\n",
    "plt.axhline(rmse_ser[5], color='Purple', label = 'Default k-value(5)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Five Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the best five features: horse power, city mpg and Curb weight\n",
    "features = ['highway-mpg','horsepower','city-mpg','curb-weight','width']\n",
    "k = [1,3,5,7,9]\n",
    "\n",
    "rmse_five = {}\n",
    "per_feature = []\n",
    "\n",
    "for i in k:\n",
    "    p = i\n",
    "    tr_col = features\n",
    "    tar_col = 'price'\n",
    "    result = knn_train_test(p, tr_col, tar_col, normalized_cars)\n",
    "    rmse_five[i] = result\n",
    "\n",
    "rmse_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the result\n",
    "\n",
    "rmse_ser = pd.Series(rmse_five)\n",
    "rmse_ser.plot(label='Price',figsize=(12,5))\n",
    "plt.xlabel('K Values')\n",
    "plt.xticks(np.arange(1, 10, step=2))\n",
    "plt.title('Predicting Price by Varying K-Value Based on The best five features')\n",
    "plt.axhline(rmse_ser[5], color='Green', label = 'Default k-value(5)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe summarizing the result\n",
    "by_rank = [rmse_two, rmse_three, rmse_four, rmse_five]\n",
    "by_rank_df = pd.DataFrame(by_rank)\n",
    "\n",
    "#transpose the data\n",
    "by_rank_df = by_rank_df.transpose()\n",
    "\n",
    "#Change the column names\n",
    "col_names = ['best_two', 'best_three','best_four','best_five']\n",
    "by_rank_df.columns = col_names\n",
    "\n",
    "by_rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the result\n",
    "\n",
    "by_rank_df.plot(figsize=(12,6))\n",
    "plt.xticks(np.arange(1,10,2))\n",
    "plt.xlabel('Varying K Values')\n",
    "#plt.grid()\n",
    "plt.title('Visualizing the Best Set of Features')\n",
    "plt.axvline(5, color = 'Black', label = 'Default k value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting The Best K Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From the visualization above, the best two features produced the least root mean square error for all k values above, we will analyse which is the best k value to use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['highway-mpg','horsepower']\n",
    "\n",
    "rmse_two = {}\n",
    "\n",
    "for i in range(1,25):\n",
    "    p = i\n",
    "    tr_col = features\n",
    "    tar_col = 'price'\n",
    "    result = knn_train_test(p, tr_col, tar_col, normalized_cars)\n",
    "    rmse_two[i] = result\n",
    "\n",
    "rmse_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the result\n",
    "\n",
    "#rmse_ser = pd.Series(rmse_five)\n",
    "pd.Series(rmse_two).plot(label='Price',figsize=(12,5))\n",
    "plt.xlabel('K Values')\n",
    "plt.xticks(np.arange(1, 26, step=1))\n",
    "plt.title('Varying K-Values Based on Best Two Features')\n",
    "#plt.axhline(rmse_ser[5], color='Green', label = 'Default k-value(5)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From the visualization above, it seems the k value of 10 gives the best result__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold and Cross Validation Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The process will now be automated using sklearn inbuilt function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(2,25):\n",
    "    kf = KFold(fold, shuffle=True, random_state=1)\n",
    "    model = KNeighborsRegressor()\n",
    "    \n",
    "    #Select the best two features\n",
    "    mses = cross_val_score(model, normalized_cars[[\"horsepower\",\"highway-mpg\"]], normalized_cars[\"price\"],\n",
    "                           scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "    rmses = np.sqrt(np.absolute(mses))\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    std_rmse = np.std(rmses)\n",
    "    \n",
    "    #Print the average rmse and standard rmse\n",
    "    print(str(fold), \"folds: \", \"avg RMSE: \", str(avg_rmse), \",\", \"std RMSE: \", str(std_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've been working under the assumption that a lower RMSE always means that a model is more accurate. This isn't the complete picture, unfortunately. A model has two sources of error, bias and variance.\n",
    "\n",
    "Bias describes error that results in bad assumptions about the learning algorithm. For example, assuming that only one feature, like a car's weight, relates to a car's fuel efficiency will lead you to fit a simple, univariate regression model that will result in high bias. The error rate will be high since a car's fuel efficiency is affected by many other factors besides just its weight.\n",
    "\n",
    "Variance describes error that occurs because of the variability of a model's predicted values. If we were given a dataset with 1000 features on each car and used every single feature to train an incredibly complicated multivariate regression model, we will have low bias but high variance. In an ideal world, we want low bias and low variance but in reality, there's always a tradeoff.\n",
    "\n",
    "The standard deviation of the RMSE values can be a proxy for a model's variance while the average RMSE is a proxy for a model's bias. Bias and variance are the 2 observable sources of error in a model that we can indirectly control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
